{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55beca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc33d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Original dataset shape: (9105, 48)\n",
      "After removing missing death values: (9105, 48)\n",
      "\n",
      "Numerical columns: 39\n",
      "Categorical columns: 8\n",
      "\n",
      "Final feature matrix shape: (9105, 47)\n",
      "Target variable shape: (9105,)\n"
     ]
    }
   ],
   "source": [
    "# 1. DATA PREPARATION\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('support2.csv')\n",
    "\n",
    "# Remove rows where target variable (death) is missing\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "df = df.dropna(subset=['death'])\n",
    "print(f\"After removing missing death values: {df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('death', axis=1)\n",
    "y = df['death']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "# Handle missing values for numerical features (median)\n",
    "if numerical_cols:\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    X[numerical_cols] = numerical_imputer.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Handle missing values for categorical features (most frequent)\n",
    "if categorical_cols:\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.values\n",
    "y = y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef504bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MODEL BUILDING FUNCTION\n",
    "def create_regularized_model(input_dim, l1_reg=1e-3, l2_reg=1e-2):\n",
    "    \"\"\"\n",
    "    Create a neural network with regularization techniques:\n",
    "    - L1 and L2 regularization\n",
    "    - Dropout\n",
    "    - Batch Normalization\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First Dense Layer with L1 and L2 regularization\n",
    "        Dense(64, \n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=l1_reg, l2=l2_reg),\n",
    "              input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Second Dense Layer with L1 and L2 regularization\n",
    "        Dense(32,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=l1_reg, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output Layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "840c31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting 5-Fold Cross-Validation\n",
      "==================================================\n",
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 Accuracy: 0.9072\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 Accuracy: 0.9072\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 Accuracy: 0.9099\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 Accuracy: 0.9121\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 Accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "# 3. K-FOLD CROSS-VALIDATION\n",
    "n_folds = 5\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting 5-Fold Cross-Validation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Normalize features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_regularized_model(\n",
    "        input_dim=X_train_fold.shape[1],\n",
    "        l1_reg=1e-3,\n",
    "        l2_reg=1e-2\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        verbose=0,  # Set to 1 to see training progress\n",
    "        validation_data=(X_val_fold, y_val_fold)\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Fold {fold} Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db52efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Average 5-Fold Accuracy (With Regularization): 0.9099\n",
      "==================================================\n",
      "\n",
      "Individual Fold Accuracies:\n",
      "Fold 1: 0.9072\n",
      "Fold 2: 0.9072\n",
      "Fold 3: 0.9099\n",
      "Fold 4: 0.9121\n",
      "Fold 5: 0.9132\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print average accuracy\n",
    "avg_accuracy = np.mean(fold_accuracies)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Average 5-Fold Accuracy (With Regularization): {avg_accuracy:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Print individual fold accuracies for reference\n",
    "print(\"\\nIndividual Fold Accuracies:\")\n",
    "for i, acc in enumerate(fold_accuracies, 1):\n",
    "    print(f\"Fold {i}: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
